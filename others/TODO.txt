1. 接收参数utils.args
2. 发送到server
3. 发送到client
4. client进行训练
5. 发送参数到server
6. 模型进行联邦聚合


3.17 
中午
1.把自定义数据集加载进来
2.写一下average这个函数
3.用一个cnn模型跑跑看


3.19
1. 完整train_dataloader, test_dataloader的添加
2. 在自己写框架的过程中，发现了很多之前没有注意到问题，和tdye讨论了这些问题，学到了不少。


3.20
上午
1. 函数注释风格
2. 完成client test部分


3.21
1. 试一下如果不联邦，集中式要怎么做，所有数据放在一起是怎么准确度

2. 添加gpu加速支持，我的电脑有gpu的（先用cpu吧）

model和inputs,labels需要加到device里面

3. 添加summary writer, tensorboard

4. 导入MNIST数据集，进行数据划分，预处理（每个客户端两个标签？）
ye好像也是直接下载的json文件


加上sh运行脚本的用法
assert用法

$'\r': command not found（sed命令）

kunkun:如何分客户端，把数据集按标签划分，然后每个客户端分到两批（附代码）


2021/3/23
1. 我想加几个参数：
集中式的算法
分布式的算法
    IID的数据集
    Non-IID的数据集

2. 加上learning rate下降 wd

3. tdye模型保存的代码以及如何保存最优模型的代码，学习别人的FL框架的代码

4. 试一下fedml video_watch_ctr集中式的代码

最好把参数存放到sh文件里，这样下次跑的时候记得

效果很好，就这样吧要学会表达和吹（不要告诉真相）

client信息为什么还是会打印出来

# 2021/3/28 框架完善任务

1. 试一下return self，然后去改写
  surrogate.update_local_dataset(self.clients[selected_clients_index[k]])  # update datasets and params
                surrogate.set_params(self.global_params)

2. 把avg放到具体的fedavg_main.py里面，这样更像一个框架

3. 学一下python lambda表达式

4. 我的代码可以复用的代码很多，建议像tdye他们那样写一个父类BASE，相同的功能代码写在这个父类里面

5. deepcopy需要注意，load_state_dict其实是传引用，所以要用deepcopy传，不然你的上一轮global_params会随着model而更新，与你预想的会不一样的。  这个bug郑舒他们查了很久才发现的（主要这个bug不会保存，不容易发现）


6. federated 这里train和test两个功能应该包裹成两个函数，不要写在一起
一个函数里面不要写太多的功能，比如下面的federate函数，里面的train和test两个功能应该写成两个函数。一般来说一个函数的代码不要超过30行，这样阅读起来比较舒服。


# 2021/4/9
1. 下载movielens-1M数据集


# 2021/4/11
pandas data.loc[i,genre] = 1这一步非常慢（100万数据），怎么解决？保存成csv吗


分别处理users、movies、ratings等表格，最后再看情况要不要合并
添加year这一列，处理dataframe确实很慢


把集中式、iid、non-idd这几种情况整合一下
centralized = True if args.client_num_in_total == 1 else False

增加tqdm

每次选一个客户端等于集中式吗？（是的）

optimization里面加上正则化, dropout



1. movielens 评分改成0-1使用lr训练

2. 把数据集移到服务器上面，后续开始变得很大了

3. 添加参数sgd，adam +
添加data_settings集中式、iid、non-iid
def partition_data

今天的主要任务
if partition == "centralized"
elif partition == "homo"
elif "hetero"

if centralized把数据集合并到一个客户端即可

选出features和特征
跑一个集中式的试一下

整理下apply的用法

year（都减去2000？）和age需要归一化吗

另外点击率预测最后得到的是一个概率吗
我们的点击率预测（看我的博客）

 x = x.flatten(start_dim=1)

lr速度很快，考虑下dataloader速度可不可以提升

看一下网上的博客ctr的目标到底是什么


画ORC曲线

准确率维持在83%左右是为什么？跟数据集划分没关系吧？

你输出model预测错的那些样例看一下

loss为什么降不下去？

把网络加深一点？

框架是否有bug

topN推荐10个看准确率0.3%


他怎么训起来，一行行debug看下哪个地方代码写错了




0.好好debug一下

问题：用户id和电影id也要加进去。不然你用的特征太少了，很多可能同样的x，但是输出y是不同的
有很多噪音吧，模型只会输出中间值了

1. zip, user_id, movie_id也要加进去（不然有很多噪音他会都输出3
2. 参考fyn代码 + 别人深度学习movielens用了什么特征 博客https://blog.csdn.net/jackmcgradylee/article/details/79129105

你需要看更多的论文，看看别人是怎么做的
如fedctr提取表征是怎么提取的

3. movielens iid和non-iid

4. 看下别人深度学习点击率预测是怎么做的

6. MNSIT划分数据集可以用.data读取到他的数据，然后进行划分 zs

改一下框架的命名规范

至少跑出能看的结果吧？？


7.wandb.watch只能运行一次，那我就添加到surrogate里面

client total应该不用作为参数输入吧，你数据集可以决定的呀

这里train和test两个功能应该包裹成两个函数，不要写在一起
        for t in range(self.num_rounds):

调一下学习率，dropout等参数

划分时序数据应该按时间划分数据集

wandb mode写一下
如何划分noniid movielens数据集?